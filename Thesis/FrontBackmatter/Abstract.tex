%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}
There are several ways of segmenting images. In this paper we solve the Multicut Problem in order to do that, which involves structured learning of the parameters. For that task there are different ways how to define the loss function of a segmentation. So far the Hamming Loss is a common used one, which checks every edge in comparison to the ground truth. If there's no match in activity the loss rises. There are several disadvantages about that like the dependence on a very good ground truth and the discontinuity (a little shifted segmentation is rated very bad). \\
Therefore the calculation of the loss via Variation of Information is analyzed within this work, which doesn't consider the individual edges anymore. Rather one examines the segmentation's labels and penalizes area-dependent dissimilarities to the ground truth. \\
The experiments were done on the BSD-500 dataset, comparing minimization of Hamming- and Variation of Information-Loss. Against expectation latter leads to an overfit of the training data or there is no significant difference, depending on the feature space. So the expected improvements didn't occur. Though there has been found a possible explanation of this behaviour which is based on the use of SLIC-Superpixels.

\newpage
\vfill

\begin{otherlanguage}{ngerman}
\pdfbookmark[1]{Zusammenfassung}{Zusammenfassung}
\chapter*{Zusammenfassung}
Es existieren verschiedene Wege zur Segmentierung von Bildern. In dieser Arbeit wird dies über das Lösen des Multicut Problems realisiert, was ein strukturelles Lernen der Parameter mit sich bringt. Hierzu gibt es verschiedene Arten, wie die Loss Funktion einer Segmentierung definiert werden kann. Eine bisher oft verwendete Methode ist der Hamming Loss, bei der jede einzelne Kante mit der Ground Truth verglichen wird und bei fehlender Übereinstimmung der Loss steigt. Dies hat verschiedene Nachteile wie die Abhängigkeit einer sehr guten Ground Truth, sowie die Unstetigkeit (eine minimal verschobene Segmentierung wird als extrem schlecht eingestuft). \\
Daher wird in dieser Arbeit die Berechnung des Losses mittels Variation of Information untersucht. Hierbei betrachtet man nicht mehr die einzelnen Kanten, sondern die Labels der Segmentierung und bestraft flächenabhängig Unterschiede zur Ground Truth. \\
Die Experimente wurden auf dem BSD-500 Datensatz durchgeführt, wobei die Minimierung des Hamming- und Variation of Information-Losses verglichen wurde. Wider den Erwartungen führt Letzteres allerdings je nach Feature Space entweder zu einem Overfit der Trainingsdaten oder zu keiner signifikanten Veränderung, wodurch die erhofften Verbesserungen nicht eintraten. Es konnte allerdings eine mögliche Erklärung für dieses Verhalten gefunden werden, die auf der Verwendung der SLIC-Superpixel beruht.

\end{otherlanguage}

\endgroup			

\vfill