%************************************************
\chapter{Experimentelles Setup}\label{ch:mathtest} % $\mathbb{ZNR}$
%************************************************

\section{Trainings- und Testdaten}


Die Trainings- und Testbilder stammten vom Berkeley Segmentation Dataset (BSD-500) \cite{BSD}, welches aus natürlichen Bildern besteht. Der Datensatz ist gegliedert in einen Trainings-, Test- und Validierungsbereich, wobei die Test-Bilder genommen wurden, da hierfür State of the Art Kantendetektoren als Feature zur Verfügung standen. Sowohl das in dieser Arbeit verwendete Trainings- als auch das Testset bestand schließlich aus $100$ Bildern. \\

Die Ground Truth der verwendeten Bilder stammen ebenfalls aus dem BSD-500 Datensatz und lagen in Form eines Pixel-Labelings vor, d.h. jedem Pixel ist eine Zahl zugeordnet, zu welchem Segment es gehört. Letztendlich will man allerdings das Labeling der zuvor berechneten Superpixel haben. Hierzu wird durch alle Superpixel iteriert und jeweils die Anzahl der Label auf Pixelebene gezählt. Dem Superpixel wird nun dasjenige Label zugeordnet, welches am häufigsten auf Pixelebene vorkommt (Majority Vote). 

Ein Beispiel findet sich in Abb. \ref{fig:gt-labels-sp}: Die farbigen Bereiche entsprechen dem Pixel-Labeling der Ground Truth, außerdem ist das Bild zuvor durch den SLIC-Alorithmus in 4 Superpixel eingeteilt worden. Für jeden Superpixel wird nun geschaut, welches Label am Häufigsten vorkommt. Für die zwei linken Superpixel ist dies der violette, oben rechts offensichtlich der blaue und unten rechts der grüne Bereich. Bei der Ground Truth ist somit nur die linke Kante inaktiv. 

\vspace{1cm}

\begin{figure}[H]
	\centering
	\includegraphics[width=.6\linewidth]{gfx/gt-labels-sp.png}
\end{figure}
\captionof{figure}{Ground Truth Labeling (farbige Bereiche) und Kanten der Superpixel vom SLIC-Algorithmus in rot}
\label{fig:gt-labels-sp}
\vspace{1cm}

\section{Graphical Model Unterbau und Solver}


Zur Generierung des Region Adjacency Graphs, des Random Forests und der Filter wurde VIGRA \cite{VIGRA}, eine Bibliothek zur Bildanalyse- und Bearbeitung, verwendet. Inferno \cite{Inferno} fand Anwendung beim Zusammenführen aller Daten, Lösen des Multicut Problems und Lernen der Parameter sowohl mit SubGradient bezüglich Hamming Loss, als auch mit Stochastic Gradient bezüglich Variation of Information. Beide Bibliotheken basieren auf C++, welche allerdings über Python angesteuert werden können. Daher wurde das komplette Programm für diese Arbeit in Python realisiert.



\section{Feature Space}\label{sec:exp_featureSpace}

Der Feature Space wurde folgendermaßen zusammengesetzt:

\begin{itemize}
	\item Gaussian Gradient Magnitude mit $\sigma=\{1, 2, 5\}$
	\item Hessian of Gaussian Eigenvalues mit $\sigma=2$
	\item Laplacian of Gaussian
	\item Structure Tensor Eigenvalues
	\item Canny Filter
	\item $N^4$-Fields Kantendetektor \cite{n4} mit und ohne Gewichtung auf Länge der Kante
	\item Structured Forests Kantendetektor \cite[Dollár et al.]{dollar} mit und ohne Gewichtung auf Länge der Kante
	\item Statistische Kenndaten in variablen Bereichen $\bar{u}$ und $\bar{v}$ um eine Kante an Superpixeln u und v (siehe Abb. \ref{fig:var-bereich-sp}) \\
	(seperat angewandt auf alle 3 Farbkanäle des eigentlichen Bildes, als auch auf den $N^4$-Fields- und Dollár-Kantendetektor)
	\begin{itemize}
		\item Mean($\bar{u} + \bar{v}$)
		\item Variance($\bar{u} + \bar{v}$)
		\item $\frac{\max{\{\text{Mean}(\bar{u}), \text{Mean}(\bar{v}) \}}}{\min{\{\text{Mean}(\bar{u}), \text{Mean}(\bar{v})}\}}$
		\item $\frac{\max{\{\text{Median}(\bar{u}), \text{Median}(\bar{v}) \}}}{\min{\{\text{Median}(\bar{u}), \text{Median}(\bar{v})}\}}$
		\item Skewness($\bar{u} + \bar{v}$)
		\item Kurtosis($\bar{u} + \bar{v}$)
	\end{itemize}
	\item Konstantes Feature für jede Kante, zur Beseitigung des Bias im Feature Space
\end{itemize}

In Abb. \ref{fig:n4} und \ref{fig:filters} sind einige Filter dargestellt. 

\newpage

\begin{figure}[H]
	\centering
	\includegraphics[width=.65\linewidth]{gfx/kanten-gewichtung-pixel-sp.png}
\end{figure}
\captionof{figure}{Pixel und Kanten auf Pixelebene ($u_i$ und $v_i$), als auch auf Superpixelebene ($u$ und $v$)}
\label{fig:kanten-gewichtung-pixel-sp}
\vspace{0.5cm}

Um nun aus diesen Pixelinformationen der Filter die Gewichtungen der Superpixelkanten zu bekommen (veranschaulicht in Abb. \ref{fig:kanten-gewichtung-pixel-sp}) werden zunächst die Kantengewichte auf Pixelebene berechnet. Bei Pixel $u_i$ und $v_i$ beträgt das zugehörige Kantengewicht:
\begin{equation}
	E_{i}=\frac{u_i+v_i}{2}
\end{equation} 
Anschließend wird der Mittelwert der Pixelkanten, welche zu einer Superpixelkante gehören, gebildet. 
\begin{equation}
E_{uv} = \frac{1}{N} \sum\limits_{i=1}^{N} E_i
\end{equation}

Dies ist die gewünschte Gewichtung der Superpixelkante. \\


Zusätzlich wurde aus den Feature Spaces aller Trainingsdaten ein Random Forest aufgebaut und dieser zur Generierung eines Weiteren (RF Feature) verwendet.

\vspace{1cm}

\begin{figure}[H]
	\centering
	\includegraphics[width=.65\linewidth]{gfx/bereich-um-sp.png}
\end{figure}
\captionof{figure}{Variable Bereiche um Kante der Superpixel u und v}
\label{fig:var-bereich-sp}
\vspace{0.5cm}

\newpage

In Abb. \ref{fig:n4} sind Beispiele für den state-of-the-art Kantendetektor $N^4$-Fields. Man sieht deutlich, dass Objektgrenzen registriert werden obwohl der Gradient aufgrund der Farbunterschiede nicht sonderlich hoch ist, beispielsweise am oberen Kopfende des Eisbärs. Allerdings arbeiten auch diese Filter nicht perfekt, wie man am unteren Bereich der Hose des Mannes bei \ref{fig:n4-3} sieht, diese Objektgrenze wird nicht sehr scharf registriert. 

%\newpage

\begin{figure}[H]
	\centering
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/183066.jpg}}
	\hfill
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/183066.png}}
	
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/64061.jpg}
	\label{fig:n4-3}}
	\hfill
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/64061.png}}
	
	\caption{Beispiele $N^4$-Fields Kantendetektor}
	\label{fig:n4}
\end{figure}

%\captionof{figure}{Beispiele $N^4$-Fields Kantendetektor}



\begin{figure}[p]
	\centering
	%\subfloat[]
	%{\includegraphics[width=.49\linewidth]{gfx/183066.jpg}}
	
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/gradMag1.png}}
	\hfill
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/gradMag2.png}}
	
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/HessEV1.png}}
	\hfill
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/HessEV2.png}}

	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/LoG.png}}
	\hfill
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/canny.png}}
	
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/structureTensor1.png}}
	\hfill
	\subfloat[]
	{\includegraphics[width=.49\linewidth]{gfx/structureTensor2.png}}
	
	\captionof{figure}{Output verschiedener Filter auf Pixelebene: (a)\&(b) Gradient Magnitude mit $\sigma=\{1, 2\}$, (c)\&(d) Hessian of Gaussian Eigenvalues, (e) Laplacian of Gaussian, (f) Canny, (g)\&(h) Structure Tensor Eigenvalues }
	\label{fig:filters}
\end{figure}



%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
