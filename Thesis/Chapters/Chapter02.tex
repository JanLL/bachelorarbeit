%*****************************************
\chapter{Theoretische Grundladen}\label{ch:theoretischeGrundlagen}
%*****************************************
\section{Graphen Theorie}\label{sec:graphTheory}

Die Grundlage aller weiteren Betrachtungen ist ein Region Adjacency Graph (RAG). Um diesen zu erstellen, wird das Bild zunächst mithilfe des SLIC-Algorithmus (Zitat!) in Superpixel unterteilt, dessen Ränder möglichst an den Objektkonturen verlaufen. Das Ergebnis hiervon ist in (Abb verlinken) abgebildet. 

Der Region Adjacency Graph G baut sich aus Nodes V und Edges E auf. In unserem Fall entsprechen die Nodes den Superpixeln. Die Edges bestehen nur zwischen denjenigen Nodes, bei denen die zugehörigen Superpixel direkt angrenzen und somit eine gemeinsame Kante besitzen. 

(hier SLIC-partition Bild und RAG-Bild einfügen)




Bei der letztlichen Segmentierung geht es darum, ein konsistentes Labeling der Superpixel zu erreichen. Dies wird über die Aktivität der Edges erreicht, welche an- oder ausgeschaltet sein können. Für die Aktivität einer Edge $y$ gilt somit: $y \in \{\text{0, 1}\}$ \\
Konsistent ist eine Segmentierung genau dann, wenn bei aktiven Edges die zugehörigen Superpixel verschiedene Labels haben und analog bei inaktiven Edges die Superpixel die gleichen Labels. Anschaulich gesehen ist dies der Fall, wenn alle aktiven Edges geschlossene Linien bilden.


\section{Feature Space}\label{sec:featureSpace}

Der Feature Space $X \in \mathbb{R}^{|E|xD}$ ordnet jeder Edge D Features zu, die möglichst in Korrelation zur Frage stehen, ob die betrachtete Edge nun aktiv oder inaktiv sein soll. 



\section{Das Multicut Problem}\label{sec:multicutProb}

Anhand dieser gewichteten Edges eine konsistente Segmentierung zu erhalten wird als Multicut Problem (MP) bezeichnet. Es wird durch folgendes Minimierungsproblem beschrieben: 


\begin{equation} 
\begin{array}{rrclcl}
\displaystyle arg \min_{y_e} & \sum\limits_{y \in E} w \beta_e \cdot y \\
\textrm{s.t.} &  y - \sum\limits_{y_i \in P(y)} y_i & \le & 0 & & \forall \ y \in E
\end{array}
\end{equation}

Hierbei entspricht $w \in \mathbb{R}^D$ den Weights und $\beta_e \in \mathbb{R}^D$ den Funktionswerten der D extrahierten Informationen des Feature Spaces. Die Nebenbedingungen erzwingen die Konsistenz der Segmentierung. $P(y)$ ist hierbei der kürzeste Pfad über inaktive Edges der beiden Superpixel, die benachbart zu $y$ sind. In der Praxis wird das Minimierungsproblem zunächst ohne Constraints gelöst und anschließend solange für Edges hinzugefügt, die die Konsistenzbedingung verletzen, bis Konsistenz erreicht ist.

\section{Loss Funktionen}

Mithilfe einer Loss Funktion $\mathcal{L}(y, y^*)$ wird quantifiziert, wie gut eine Segmentierung $y$ mit derjenigen der Ground Truth $y^*$ übereinstimmt. In dieser Arbeit wird die neue Methode "Variation of Information" vorgestellt und mit der bestehenden "Partition Hamming" verglichen.

\subsection{Partition Hamming}

\begin{equation}
\mathcal{L}(y_i, y_i^*) = \left\{ \begin{array}{lcc}  
\mathbb{I}[y_i \neq y_i^*] \cdot \alpha_{over} & \text{if} & y_i^* = 0  \\ 
\mathbb{I}[y_i \neq y_i^*] \cdot \alpha_{under} & \text{if} & y_i^* = 1         
\end{array}  \right.  \quad \forall y_i \in E 
\end{equation}

\begin{equation}
\mathcal{L}(y, y^*) = \sum\limits_{y_i \in E} \mathcal{L}(y_i, y_i^*)
\end{equation}


Es werden direkt die Edges der Segmentierung $y$ und der Ground Truth $y^*$ verglichen und bei fehlender Übereinstimmung erhöht sich der Loss. Meist ist $\alpha_{under} > \alpha_{over}$ um Übersegmentierung zu bevorzugen, da es tragischer ist Objekte nicht zu erfassen.

\subsection{Variation of Information}\label{sec:voi}

\begin{equation}
\mathcal{L}(y, y^*) = H_y + H_{y^*} - 2 \cdot I(y, y^*)
\end{equation}

$H_x$ ist hierbei die Entropie der Segmentierung $x$. Jede Segmentierung besitzt eine individuelle Entropie.  \\
$I(x, x^*)$ bezeichnet die Transinformation, anschaulich gesehen entspricht diese der Schnittmenge der Ist- und Soll-Segmentierung. 
Es werden also die Labels der Superpixel untersucht und bei fehlender Übereinstimmung beim Vergleich mit der Ground Truth erhöht sich der Loss.

\section{Structured Learning}\label{sec:strucLearn}

Um später mithilfe des Multicut Algorithmus Bilder möglichst gut segmentieren zu können, muss der Parameter $w$ bestimmt werden. "Möglichst gut" bedeutet hier in Bezug auf eine Loss Funktion, die als Qualitätskriterium dient. Da ein niedriger Loss für eine gute Segmentierung steht ist also das folgende Minimierungsproblem zu lösen:

\begin{equation}
\hat{w} = arg\min_{w} \mathcal{L}(y, y^*)
\end{equation}

\subsection{Subgradient Descent}

Der Subgradient Descent Algorithmus basiert auf der Berechnung der Differenz der akkumulierten Feature der Segmentierung $y$ und der Ground Truth $y^*$, welche gewichtet dem weight Vector $w$ hinzuaddiert werden. Für nähere Details siehe \cite{NowozinStrucLearn11}.

Die Minimierung des Partition Hamming Losses in dieser Arbeit wird hiermit realisiert.

\subsection{Stochastic Gradient}

Der hier verwendete Stochastic Gradient ist eine Variante des in \cite{NowozinStrucLearn11} näher erläuterten Algorithmus. Nachdem wie gewöhnlich bei Stochastic Gradient ein zufälliges Training Sample gewählt wurde, wird folgendermaßen die Gradientenrichtung bestimmt: Es wird zum momentanen Weight Vector nPerturbs mal ein normalverteilter Noise hinzuaddiert. Für jeden dieser verrauschten Weights wird der Loss bezüglich des momentan betrachteten Bildes berechnet. 
Es wird nun, gewichtet nach der Veränderung im Loss, aus dem Noise die Gradientenrichtung berechnet. Je stärker der Loss gestiegen ist, desto größer ist sein Einfluss auf die neue Richtung. Analog mit gesunkenem Loss.

Die beste Schrittweite wird nun ermittelt, indem der durchschnittliche Loss über das gesamte Trainingsset für verschiedene äquidistante Schrittweiten berechnet wird. Es wird diejenige Schrittweite mit dem niedrigsten Loss gewählt und falls ein neues globales Minimum gefunden wurde, der weight Vector gespeichert. \\

vllt später mal so... :
\begin{algorithm}
\caption{Stochastic Gradient Descent}\label{sgd}
\begin{algorithmic}[1]
\Procedure{StochasticGradientDescent($T, \eta$)}{}
\EndProcedure
\end{algorithmic}
\end{algorithm}









%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
