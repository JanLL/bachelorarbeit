%*****************************************
\chapter{Theoretische Grundladen}\label{ch:theoretischeGrundlagen}
%*****************************************
\section{Graphen Theorie}\label{sec:graphTheory}

Die Grundlage aller weiteren Betrachtungen ist ein Region Adjacency Graph (RAG). Um diesen zu erstellen, wird das Bild zunächst mithilfe des SLIC-Algorithmus \cite{slic} in Superpixel unterteilt, dessen Ränder möglichst an den Objektkonturen verlaufen. 

Der Region Adjacency Graph G baut sich aus Knoten V und Kanten E auf. In unserem Fall entsprechen die Nodes den Superpixeln. Die Kanten bestehen nur zwischen denjenigen Nodes, bei denen die zugehörigen Superpixel direkt angrenzen und somit eine gemeinsame Kante besitzen. 

Sowohl die resultierende Superpixel-Partitionierung mittels SLIC, als auch eine Demonstration, wie daraus der Region Adjacency Graph entsteht, sind in Abb. \ref{fig:slic-rag} dargestellt.

\begin{figure}[H]

	\centering
	\subfloat[SLIC Superpixels]
	{\includegraphics[width=.49\linewidth]{gfx/slic.png}}
	\hfill
	\subfloat[Region Adjacency Graph aus Superpixels, Knoten: grüne Punkte, Kanten: blaue Linien]
	{\includegraphics[width=.49\linewidth]{gfx/rag2.png}}
\end{figure}
\captionof{figure}{Beispiel einer Superpixel Partitionierung mittels SLIC}
\label{fig:slic-rag}

\vspace{0.5cm}


Bei der Segmentierung geht es darum, ein konsistentes Labeling der Superpixel zu erreichen. Dies wird über die Aktivität der Kanten erreicht, welche an- oder ausgeschaltet sein können. Für die Aktivität einer Kante $y$ gilt somit: $y \in \{\text{0, 1}\}$, wobei $1$ aktiv und 0 inaktiv bedeutet \\
Konsistent ist eine Segmentierung genau dann, wenn bei aktiven Kanten die zugehörigen Superpixel verschiedene Labels haben und analog bei inaktiven Kanten die Superpixel die gleichen Labels. Anschaulich gesehen ist dies der Fall, wenn alle aktiven Kanten geschlossene Linien bilden.


\section{Feature Space}\label{sec:featureSpace}

Der Feature Space $X \in \mathbb{R}^{|E|xD}$ ordnet jeder Kante D Features zu, die möglichst in Korrelation zur Frage stehen, ob die betrachtete Kante nun aktiv oder inaktiv sein soll. Zu den in dieser Arbeit verwendeten Feature wird in \ref{sec:exp_featureSpace} genauer eingegangen.



\section{Das Multicut Problem}\label{sec:multicutProb}

Anhand dieser, durch den Feature Space, gewichteten Kante eine konsistente Segmentierung zu erhalten wird als Multicut Problem (MP) bezeichnet. Es wird durch folgendes Minimierungsproblem beschrieben: 


\begin{equation} 
\begin{array}{rrclcl}
\displaystyle arg \min_{y} & \sum\limits_{y_i \in E} \langle w, \beta_e \rangle \cdot y_i \\
\textrm{s.t.} &  y - \sum\limits_{y_i \in P(y)} y_i & \le & 0 & & \forall \ y \in E
\end{array}
\label{eq:mp}
\end{equation}


Hierbei entspricht $w \in \mathbb{R}^D$ den Weights der einzelnen Feature und $\beta_e \in \mathbb{R}^D$ den Funktionswerten der D extrahierten Informationen des Feature Spaces. Die Nebenbedingungen erzwingen die Konsistenz der Segmentierung. $P(y)$ ist hierbei der kürzeste Pfad über inaktive Kanten der beiden Superpixel, die benachbart zu $y$ sind. In der Praxis wird das Minimierungsproblem zunächst ohne Constraints gelöst und anschließend solange für diejenigen Kanten hinzugefügt, die die Konsistenzbedingung verletzen, bis Konsistenz erreicht ist.

\section{Loss Funktionen}\label{sec:loss-fkts}

Mithilfe einer Loss Funktion $\mathcal{L}(y, y^*)$ wird quantifiziert, wie gut eine Segmentierung $y$ mit derjenigen der Ground Truth $y^*$ übereinstimmt. In dieser Arbeit wird die Methode Variation of Information vorgestellt und mit der bestehenden des Hamming Loss verglichen.

\subsection{Hamming Loss}

\begin{equation}
\mathcal{L}_i(y_i, y_i^*) = \left\{ \begin{array}{lcc}  
\mathbb{I}[y_i \neq y_i^*] \cdot \alpha_{over} & \text{if} & y_i^* = 0  \\ 
\mathbb{I}[y_i \neq y_i^*] \cdot \alpha_{under} & \text{if} & y_i^* = 1         
\end{array}  \right.  \quad \forall y_i \in E 
\end{equation}

\begin{equation}
\mathcal{L}_H(y, y^*) = \sum\limits_{y_i \in E} \mathcal{L}_i(y_i, y_i^*)
\end{equation}


Es werden direkt die Kanten der Segmentierung $y$ und der Ground Truth $y^*$ verglichen und bei fehlender Übereinstimmung erhöht sich der Loss. Meist ist $\alpha_{under} > \alpha_{over}$ um Übersegmentierung zu bevorzugen, da es tragischer ist Objekte nicht zu erfassen, als sie in mehreren Teilen vorzufinden. 

\subsection{Variation of Information}\label{sec:voi}

\begin{equation}
\mathcal{L}_{VOI}(y, y^*) = H_y + H_{y^*} - 2 \cdot I(y, y^*)
\end{equation}

\begin{equation}
H_y = \mathbb{E}[\hat{I}(y)] = - \sum\limits_{l \in y} p(l) \cdot log_e( p(l) )
\end{equation}

\begin{equation}
I(y, y^*) = \sum\limits_{l_1 \in y} \sum\limits_{l_2 \in y^*} p(l_1, l_2) \cdot log_e \left( \frac{p(l_1, l_2)}{p(l_1) p(l_2)} \right)
\end{equation}

$H_y$ ist hierbei die Entropie des Labelings $y$, welche als Erwartungswert der Information $\hat{I}$  definiert ist. Jede Segmentierung besitzt eine individuelle Entropie.  \\
$I(y, y^*)$ bezeichnet die Transinformation, anschaulich gesehen entspricht diese der Schnittmenge der Ist- und Soll-Segmentierung. 
Es werden also die Labels der Superpixel untersucht und bei fehlender Übereinstimmung beim Vergleich mit der Ground Truth erhöht sich der Loss.

\section{Structured Learning}\label{sec:strucLearn}

Allgemein wird beim Lernprozess eine Abbildung $f: X \rightarrow Y$ gesucht, welche die Feature $X$ in einen Output $Y$ überführt. Der Hauptunterschied zum unstrukturierten Lernen besteht nun in der Form dieses Outputs. Je nach Klassifikations- oder Regressionsproblem besteht beim unstrukturierten Lernen der Output entweder aus Klassen oder reellen Zahlen. Beim strukturierten Lernen hingegen existiert ein zulässiges Set an Outputs, welche einer gewissen Struktur genügen. In unserem Fall ist diese Struktur die konsistente Segmentierung. Man kann unser Problem auch als Klassifikationsproblem der Kanten mit Nebenbedingungen betrachten. Da somit die einzelnen Outputs $y \in Y$ miteinander in Verbindung stehen, muss beim Lernprozess der Loss gemeinsam für alle $y$ berechnet werden.

Beim Multicut Problem \eqref{eq:mp} wird $f$ durch die Weights $w$ spezifiziert, welche je nach Abstiegsverfahren und Loss unterschiedlich erlangt werden. Die konkreten Methoden werden in den folgenden Kapiteln erläutert. 

Ein weiterer Unterschied besteht in der Wahl der Loss-Funktion, welche in Kapitel \ref{sec:loss-fkts} vorgestellt wurden. Beim unstrukturierten Lernen wird bei der Klassifikation oft der 0-1-Loss genommen, bei dem der Output entweder der Ground Truth entspricht, oder eben nicht. Aufgrund der Struktur der Lösung ist dies hier allerdings nicht sonderlich sinnvoll da es eben schlechtere und bessere Segmentierungen gibt und diese Abstufungen unterschieden werden sollten, was beispielsweise durch die genannten Loss Funktionen ermöglicht wird.


%Um später mithilfe des Multicut Algorithmus Bilder optimal segmentieren zu können, muss der Parameter $w$ aus \eqref{eq:mp} bestimmt werden. 

%\grqq Optimal\grqq \ bedeutet hier in Bezug auf eine Loss Funktion, die als Qualitätskriterium dient. Da ein niedriger Loss für eine gute Segmentierung steht ist also das folgende Minimierungsproblem zu lösen:

%\begin{equation}
%\hat{w} = arg\min_{w} \mathcal{L}(y, y^*)
%\end{equation}

\subsection{Subgradient Descent}

Der Subgradient Descent Algorithmus basiert auf der Berechnung der Differenz der akkumulierten Feature der Segmentierung $y$ und der Ground Truth $y^*$, welche gewichtet den Weights $w$ hinzu addiert werden. In \cite{NowozinStrucLearn11} wird der Algorithmus ausführlich ausgeführt. 

Die Berechnung des Loss findet hierbei beim Lösen des Multicut Problems statt, sodass dieses wie folgt aussieht:

\begin{equation} 
\begin{array}{rrclcl}
\displaystyle arg \min_{y} & \sum\limits_{y_i \in E} \langle w, \beta_e \rangle \cdot y_i + \mathcal{L}_H(y, y^*) \\
\textrm{s.t.} &  y - \sum\limits_{y_i \in P(y)} y_i & \le & 0 & & \forall \ y \in E
\end{array}
\label{eq:mp-hamming}
\end{equation}

Die Minimierung des Hamming Loss wird in dieser Arbeit hiermit realisiert.

\subsection{Stochastic Gradient}

Der hier verwendete Stochastic Gradient ist eine Variante des in \cite{NowozinStrucLearn11} näher erläuterten Algorithmus. Anders als beim Subgradient Descent wird hier zunächst das Multicut Problem ohne Loss \eqref{eq:mp} gelöst und anschließend der Loss der resultierenden Segmentierung berechnet.

Im folgenden wird die hier angewandte Methode zur Ermittlung der Gradientenrichtung (Alg. \ref{alg:sg_dir}), sowie der Liniensuche (Alg. \ref{alg:sgd_ls}), also der Schrittweite pro Iterationsschritt beschrieben: \\

\begin{algorithm}[H]
\caption{Get Gradient Descent Direction}\label{alg:sg_dir}
\begin{algorithmic}[1]
\Procedure{GetGradientDescentDirection($\#Perturbs, \sigma$, $w$)}{}
	\State $\sigma$: Noise standard deviation
	\State $w$: Current Weight Wector
	\State
	\State $\Delta x = 0$
	\For{$n=1 ... \#Perturbs$}
		\State Generate Noise $\in \mathcal{N}(0, \sigma^2)$ und add to $w$
		\State Calculate Loss on current Training Sample
		\State $\Delta x = \Delta x + Noise*Loss$
	\EndFor
	\State $\Delta x = -\Delta x / \#Perturbs$
	\State \Return{$\Delta x$}
\EndProcedure
\end{algorithmic}
\end{algorithm}

Um die Gradientenrichtung zu bestimmen wird zunächst in \#Perturbs verschiedene normalverteilte Richtungen, vom momentanen Weight Vector aus, der Loss auf dem aktuellen Bild berechnet. Anschließend werden die einzelnen Richtungen nach ihrem Loss gewichtet, wodurch man eine Richtung starken Anstieges ermittelt hat. Daher ist am Ende noch ein Vorzeichenwechsel nötig.

\vspace{1cm}


\begin{algorithm}[H]
\caption{Line Search and update Weights}\label{alg:sgd_ls}
\begin{algorithmic}[1]
\Procedure{LineSearchAndTakeStep($w, \eta, \Delta x$)}{}
	\State $\eta$: Stepwidth
	\State $w$: Current weight vector
	\State $\Delta x$: Gradient Descent Direction
	\State
	\For{$n=\{0.1, 0.5, 1.0, 5.0, 10.0\}$}
		\State Varied Weight Vector $w_{var} = w + \Delta x \cdot n$
		\State Calculate mean Loss $\mathcal{L}$ on entire Training Set
		\State from $w_{var}$
		\If{$\mathcal{L} < \mathcal{L}_{best}$}
			\State $\mathcal{L}_{best} = \mathcal{L}$
			\State Save $w_{best} = w$
			\State Break
		\EndIf
		\State Memorize $\mathcal{L}$ and associated varied Weight Vector
	\EndFor
	\State $w = w_{var}$, where regarding Loss is minimal
	\State \Return $w$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\vspace{0.5cm}

Für äquidistant gewählte Schrittweiten über 2 Größenordnungen wird jeweils der Mittelwert des Losses auf dem gesamten Trainingsset ermittelt und mit dem bisher besten Wert verglichen. Bei Erreichen eines neuen Tiefpunktes, wird direkt dorthin gesprungen, andernfalls wird die Schrittweite mit dem Niedrigsten erreichten Loss gewählt.







%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
