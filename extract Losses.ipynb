{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import vigra\n",
    "from vigra import graphs\n",
    "import copy\n",
    "import os\n",
    "import pylab\n",
    "import time\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import inferno\n",
    "import multicutAuxFunctions as maf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data...\n",
      "[==================================================] 100%\n",
      "Building up Training Feature Space...\n",
      "[==================================================] 100%\n",
      "Time to built up Training Feature Space: 0.181408166885 sec\n",
      "Load previous partitionHammingWeights\n",
      "Loading Random Forest...\n",
      "Get probabilities from Random Forest...\n",
      "Loading previous VOI weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/pyplot.py:412: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_num_figures`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "resultsPath = 'results/151211_weightsIn[0,1]_ph_w\\oRf_w\\oConstr_voi_w\\RF_w\\oConstrOnRF_origGradDirSearch/'\n",
    "\n",
    "################################### Training Data ########################################\n",
    "\n",
    "trainSetPath = 'trainingSet/'\n",
    "#trainSetPath = 'fewImages/'\n",
    "\n",
    "\n",
    "path = os.walk(trainSetPath)\n",
    "\n",
    "trainingIds = []\n",
    "trainingImgs = []\n",
    "\n",
    "trainingGtLabels = []\n",
    "trainingGtSols = []\n",
    "\n",
    "trainingRags = []\n",
    "\n",
    "superpixelDiameter = 20      # super-pixel size\n",
    "slicWeight         = 25.0    # SLIC color - spatial weight\n",
    "nodeNumStop        = 50      # desired num. nodes in result\n",
    "minSize            = 15\n",
    "\n",
    "print \"Loading Training Data...\"\n",
    "############# load images and convert to LAB #############\n",
    "for root, dirs, files in path:\n",
    "    jpgFiles = [filename for filename in files if filename.endswith('.jpg')]\n",
    "    T = len(jpgFiles)\n",
    "    for i, filename in enumerate(jpgFiles):\n",
    "        \n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(\"[%-50s] %d%%\" % ('='*int(float(i+1)/T*50), int(float(i+1)/T*100)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        fileId = filename[:-4]\n",
    "        trainingIds.append(fileId)\n",
    "        \n",
    "        img = vigra.impex.readImage(root + '/' + filename)\n",
    "        trainingImgs.append(img)\n",
    "        imgLab = vigra.colors.transform_RGB2Lab(img)\n",
    "            \n",
    "        gridGraph = graphs.gridGraph(img.shape[0:2])\n",
    "\n",
    "        slicLabels = vigra.analysis.labelImage(vigra.analysis.slicSuperpixels(imgLab, slicWeight, superpixelDiameter, minSize=minSize)[0])\n",
    "        rag = graphs.regionAdjacencyGraph(gridGraph, slicLabels)\n",
    "        trainingRags.append(rag)\n",
    "        \n",
    "        #gtWatershed = loadmat('trainingSet/groundTruth/' + fileId + '.mat')['groundTruth'][0,0][0][0][0]\n",
    "        #gtLabel = maf.getSuperpixelLabelList(rag, gtWatershed)\n",
    "        \n",
    "        gtLabel = np.load('groundTruthLabels/' + fileId + '.npy')\n",
    "\n",
    "\n",
    "        trainingGtLabels.append(gtLabel)\n",
    "        trainingGtSols.append(maf.getGroundTruthSol(rag, gtLabel))\n",
    "        \n",
    "        \n",
    "        \n",
    "### Feature Spaces\n",
    "# Training\n",
    "\n",
    "#testingFeatureSpacesPath = resultsPath + 'featureSpaces/training/'\n",
    "\n",
    "trainingFeatureSpaces = []\n",
    "trainingEdges = []\n",
    "t1 = time.time()\n",
    "T = len(trainingImgs)\n",
    "print \"\\nBuilding up Training Feature Space...\"\n",
    "sys.stdout.flush()\n",
    "for i, (rag, img, trainId) in enumerate(zip(trainingRags, trainingImgs, trainingIds)):\n",
    "    trainingEdges.append(rag.uvIds().astype('uint64'))\n",
    "\n",
    "    #if (os.path.isfile(testingFeatureSpacesPath + trainId + '.npy') == True):\n",
    "    #    features = np.load(testingFeatureSpacesPath + trainId + '.npy')\n",
    "    #    if (os.path.isfile(resultsPath + 'featureSpaces/featureNames.npy') == True):\n",
    "    #        featureNames = list(np.load(resultsPath + 'featureSpaces/featureNames.npy'))\n",
    "        \n",
    "    #else:\n",
    "    #    features, featureNames = maf.getFeatures(rag, img, trainId)\n",
    "    #    np.save(testingFeatureSpacesPath + trainId + '.npy', features)\n",
    "    #    np.save(resultsPath + 'featureSpaces/featureNames.npy', featureNames)\n",
    "        \n",
    "    features = np.load('featureSpaces/full/' + trainId + '.npy')\n",
    "    featureNames = list(np.load('featureSpaces/full/featureNames.npy'))\n",
    "\n",
    "\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(\"[%-50s] %d%%\" % ('='*int(float(i+1)/T*50), int(float(i+1)/T*100)))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    trainingFeatureSpaces.append(features)\n",
    "t2 = time.time()\n",
    "\n",
    "print \"\\nTime to built up Training Feature Space:\", t2-t1, \"sec\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################## Norm Feature Spaces to [-1, 1] ############################################\n",
    "'''\n",
    "print \"Start to change Norm of Feature Spaces to [-1, 1]...\"\n",
    "t1 = time.time()\n",
    "for n in range(len(trainingFeatureSpaces)):\n",
    "    featureSpace = trainingFeatureSpaces[n]\n",
    "    for edgeWeights in featureSpace.transpose():\n",
    "        edgeWeights *= 2\n",
    "        edgeWeights -= 1\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print \"Time to change norm on Feature Spaces: \", t2-t1\n",
    "'''\n",
    "\n",
    "\n",
    "### Load Previous partition Hamming Weights\n",
    "print \"Load previous partitionHammingWeights\"\n",
    "auxWeightVector = np.load(resultsPath + 'partitionHamming/weights.npy')\n",
    "weightVector = inferno.learning.WeightVector(auxWeightVector.shape[0], 0.0)\n",
    "for n in range(len(weightVector)):\n",
    "    weightVector[n] = auxWeightVector[n]\n",
    "    \n",
    "    \n",
    "os.makedirs(resultsPath + 'partitionHamming/trainingResults/segmentedImages/')\n",
    "maf.performTesting2(trainingImgs, trainingRags, trainingEdges, trainingFeatureSpaces, trainingIds, trainingGtLabels,\n",
    "                    featureNames, weightVector, resultsPath + 'partitionHamming/trainingResults/')\n",
    "    \n",
    "\n",
    "\n",
    "########################## Add Random Forest Feature ###################################\n",
    "\n",
    "\n",
    "print \"Loading Random Forest...\"\n",
    "RF = vigra.learning.RandomForest('featureSpaces/full/RF.hdf5')\n",
    "print \"Get probabilities from Random Forest...\"\n",
    "trainingRfProbs = maf.getProbsFromRF(trainingFeatureSpaces, RF)\n",
    "trainingFeatureSpaces[:] = [np.concatenate((featureSpace, (prob[:,1]).reshape(prob.shape[0],1)), axis=1) for featureSpace, prob in zip(trainingFeatureSpaces, trainingRfProbs)]\n",
    "\n",
    "\n",
    "featureNames.append('RF_Prob')\n",
    "nFeatures = trainingFeatureSpaces[0].shape[1]\n",
    "\n",
    "\n",
    "########################## Norm Feature Spaces to [-1, 1] (just RF Feature) ############################################\n",
    "'''\n",
    "print \"Start to change Norm of Feature Spaces to [-1, 1]...\"\n",
    "t1 = time.time()\n",
    "for n in range(len(trainingFeatureSpaces)):\n",
    "    featureSpace = trainingFeatureSpaces[n]\n",
    "    edgeWeightsRF = featureSpace.transpose()[-1]\n",
    "    edgeWeightsRF *= 2\n",
    "    edgeWeightsRF -= 1\n",
    "\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print \"Time to change norm on Feature Spaces: \", t2-t1\n",
    "\n",
    "'''\n",
    "\n",
    "    \n",
    "    \n",
    "############################ Stochastic Gradient Learner (Variation of Information) ##########################\n",
    "\n",
    "# Load Previous VOI Weights\n",
    "print \"Loading previous VOI weights\"\n",
    "auxWeightVector = np.load(resultsPath + 'VOI/weights.npy')\n",
    "weightVector = inferno.learning.WeightVector(auxWeightVector.shape[0], 0.0)\n",
    "for n in range(len(weightVector)):\n",
    "    weightVector[n] = auxWeightVector[n]\n",
    "    \n",
    "os.makedirs(resultsPath + 'VOI/trainingResults/segmentedImages/')\n",
    "maf.performTesting2(trainingImgs, trainingRags, trainingEdges, trainingFeatureSpaces, trainingIds, trainingGtLabels,\n",
    "                    featureNames, weightVector, resultsPath + 'VOI/trainingResults/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load previous partitionHammingWeights\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resultsPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-dadf79f75d86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Load Previous partition Hamming Weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Load previous partitionHammingWeights\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mauxWeightVector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultsPath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'partitionHamming/weights.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mweightVector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minferno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeightVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauxWeightVector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweightVector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resultsPath' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
